{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "path = '../../../../../../Desktop/Orthografietrainer2020/pickle/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import table and keep relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(path+'sitzungssummary.pkl','rb')\n",
    "session = pickle.load(infile)\n",
    "infile.close()\n",
    "session = session [['ID','UserID','UserAttribut','Art','HA','beendet','Fehler']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(path+'saetze.pkl','rb')\n",
    "sentences = pickle.load(infile)\n",
    "infile.close()\n",
    "sentences = sentences[['satzID','Schwierigkeit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(path+'schueler2020only.pkl','rb')\n",
    "students = pickle.load(infile)\n",
    "infile.close()\n",
    "students = students[['ID','Geschlecht','Klassenstufe','Anmeldeklassenstufe','Aufgaben','Altaufgaben','done']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open(path+'xmlsaetze.pkl','rb')\n",
    "xmlsentences = pickle.load(infile)\n",
    "infile.close()\n",
    "xmlsentences = xmlsentences[['ID','UserID','UebungsID','Testposition','SatzID','Erstloesung','Schussel','Datum', 'Erfolg','Loesungsnr']]\n",
    "\n",
    "infile = open(path+'xmlsaetze_archiv.pkl','rb')\n",
    "xmlsentences_archive = pickle.load(infile)\n",
    "infile.close()\n",
    "xmlsentences_archive = xmlsentences_archive[['ID','UserID','UebungsID','Testposition','SatzID','Erstloesung','Schussel','Datum', 'Erfolg','Loesungsnr']]\n",
    "\n",
    "xmlsentences = xmlsentences.append(xmlsentences_archive)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "clean session df\n",
    "\"\"\"\n",
    "session = session.dropna()\n",
    "session.rename(columns = {'ID':'UebungsID'}, inplace = True)\n",
    "\n",
    "## Userattribut: 1=student; 0= guest/teacher\n",
    "session['UserAttribut'] = session['UserAttribut'].replace(['SchÃ¼ler'],1)\n",
    "session['UserAttribut'] = session['UserAttribut'].replace(['Gast','Lehrer'],0)\n",
    "session[['UserAttribut']] = session[['UserAttribut']].astype('int16')\n",
    "session['HA'] = session['HA'].replace(['frHA'],'Self')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "clean students df\n",
    "\"\"\"\n",
    "students.rename(columns = {'ID':'UserID'}, inplace = True)\n",
    "students['done'] = students['done'].astype('int16')\n",
    "##clean gender\n",
    "students['Geschlecht'] = students['Geschlecht'].replace(['m.'],'m')\n",
    "students['Geschlecht'] = students['Geschlecht'].replace(['w.','we'],'w')\n",
    "students['Geschlecht'] = students['Geschlecht'].replace(['d','wm'],np.nan)\n",
    "##class level: only 5-12\n",
    "options = ['5', '6','7','8','9','10','11','12'] \n",
    "students = students[students['Klassenstufe'].isin(options)] \n",
    "students['Klassenstufe'] = students['Klassenstufe'].astype('int')\n",
    "##years registered: create new column years registered from class level and date of registration\n",
    "students = students[students['Anmeldeklassenstufe'].isin(options)] \n",
    "students['Anmeldeklassenstufe'] = students['Anmeldeklassenstufe'].astype('int')\n",
    "students['Jahredabei'] = students['Klassenstufe'] - students['Anmeldeklassenstufe']\n",
    "##Count of pending tasks: creat new column count of pending tasks\n",
    "students['Aufgaben']=students['Aufgaben'].str.split()\n",
    "students['AnzahlAufgaben'] = students['Aufgaben'].str.len()\n",
    "students['AnzahlAufgaben'] = students['AnzahlAufgaben'].replace([np.nan],0)\n",
    "students['AnzahlAufgaben'] = students['AnzahlAufgaben'].astype('int')\n",
    "##Drop columns \n",
    "students= students.drop(columns=['Anmeldeklassenstufe','Aufgaben','Altaufgaben'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merge xmlsentences with sentences\n",
    "\"\"\"\n",
    "xmlsentences.rename(columns = {'SatzID':'satzID'}, inplace = True)\n",
    "xmlsentences= pd.merge(xmlsentences, sentences, on='satzID', how='inner')\n",
    "##create date columns\n",
    "xmlsentences['Datum']= pd.to_datetime(xmlsentences['Datum'])\n",
    "xmlsentences['Uhrzeit'] = pd.DatetimeIndex(xmlsentences['Datum']).hour\n",
    "xmlsentences['Wochentag'] = pd.DatetimeIndex(xmlsentences['Datum']).dayofweek\n",
    "xmlsentences['Kalenderwoche'] = pd.DatetimeIndex(xmlsentences['Datum']).strftime(\"%V\")\n",
    "xmlsentences['Monat'] = pd.DatetimeIndex(xmlsentences['Datum']).month\n",
    "xmlsentences['Tag'] = pd.DatetimeIndex(xmlsentences['Datum']).day\n",
    "\n",
    "\"\"\"\n",
    "function that determines if task was processed during school lesson\n",
    "\"\"\"\n",
    "def f(row):\n",
    "    if row['Uhrzeit'] > 14:\n",
    "        val = 0\n",
    "    elif row['Uhrzeit'] < 8:\n",
    "        val = 0\n",
    "    else:\n",
    "        val = 1\n",
    "    return val\n",
    "xmlsentences['ist_Schulzeit'] = xmlsentences.apply(f, axis=1)\n",
    "xmlsentences = xmlsentences.drop(columns='UserID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "filter\n",
    "\"\"\"\n",
    "## only use normal exercise sets and data from march and april\n",
    "xmlsentences = xmlsentences[(xmlsentences.Testposition == 'version') | (xmlsentences.Testposition == 'pruefung') | (xmlsentences.Testposition == 'training')]\n",
    "xmlsentences = xmlsentences[(xmlsentences.Monat == 3) | (xmlsentences.Monat == 4)]#|(xmlsentences.Monat == 5) | (xmlsentences.Monat == 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create variable multiple wrong\n",
    "\"\"\"\n",
    "xmlsentences['Loesungsnr']=xmlsentences['Loesungsnr'].str.split()\n",
    "xmlsentences['MehrfachFalsch'] = xmlsentences['Loesungsnr'].str.len()\n",
    "xmlsentences['MehrfachFalsch'] = xmlsentences['MehrfachFalsch'].replace([np.nan],0)\n",
    "xmlsentences['MehrfachFalsch'] = xmlsentences['MehrfachFalsch'].astype('int')\n",
    "xmlsentences['MehrfachFalsch'] = xmlsentences['MehrfachFalsch'] - 1\n",
    "##save preprocessed dataset\n",
    "xmlsentences.to_pickle('xmlsentences_preprocessed.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate dropout from session data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infile = open('xmlsentences_preprocessed.pkl','rb')\n",
    "# xmlsentences = pickle.load(infile)\n",
    "# infile.close()\n",
    "\n",
    "#split data\n",
    "xmlsentences['group'] = xmlsentences.UebungsID % 10\n",
    "xmlsentences1 = xmlsentences[xmlsentences.group == 1]\n",
    "xmlsentences2 = xmlsentences[xmlsentences.group == 2]\n",
    "xmlsentences3 = xmlsentences[xmlsentences.group == 3]\n",
    "xmlsentences4 = xmlsentences[xmlsentences.group == 4]\n",
    "xmlsentences5 = xmlsentences[xmlsentences.group == 5]\n",
    "xmlsentences6 = xmlsentences[xmlsentences.group == 6]\n",
    "xmlsentences7 = xmlsentences[xmlsentences.group == 7]\n",
    "xmlsentences8 = xmlsentences[xmlsentences.group == 8]\n",
    "xmlsentences9 = xmlsentences[xmlsentences.group == 9]\n",
    "alle = [xmlsentences1, xmlsentences2, xmlsentences3, xmlsentences4, xmlsentences5, xmlsentences6, xmlsentences7, xmlsentences8, xmlsentences9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function to find ordernumber and break\n",
    "ordernumber == number of appearance of each sentence in a session, e.g. first sentence in a session = ordernumber 1\n",
    "break == luecke == 1 if the session was paused more than 45 minutes; 0 otherwise\n",
    "\"\"\"\n",
    "cnt = 0\n",
    "\n",
    "for x in alle:\n",
    "    cnt = cnt +1\n",
    "    num = str(cnt)\n",
    "    \n",
    "    session = x.UebungsID.unique()\n",
    "\n",
    "    ## ordernumbers df: a ordernumber is calculated for each sentence in one session\n",
    "    ordernumbers =pd.DataFrame(columns=['OrderNumber', 'ID'])\n",
    "    for i in session:\n",
    "        subset = x.loc[x['UebungsID'] == i]\n",
    "        subset = subset.sort_values(by='Datum')\n",
    "        subset = subset.reset_index(drop=True)\n",
    "        subset.reset_index(inplace=True)\n",
    "        subset = subset.rename(columns = {'index':'OrderNumber'})\n",
    "        subset = subset[['OrderNumber','ID']]\n",
    "        ordernumbers = ordernumbers.append(subset)\n",
    "\n",
    "    ## merge ordernumber df to main data set\n",
    "    x = pd.merge(x,ordernumbers,on='ID', how='left')\n",
    "\n",
    "    x['OrderNumber'] = x['OrderNumber'] + 1\n",
    "    x.to_pickle('xmlsentences'+num+'_ordernumber.pkl')\n",
    "    x['Time'] = pd.DatetimeIndex(x['Datum']).strftime(\"%X\")\n",
    "\n",
    "    ## Create new variable luecke = is 1 if session is paused more than 45 minutes; otherwise 0 \n",
    "    df_gr = x.groupby('UebungsID').agg({'Monat': ['min', 'max'], 'Tag': ['min', 'max'], 'Time': ['min', 'max']})\n",
    "    df_gr = df_gr.reset_index()\n",
    "\n",
    "    def f(row):\n",
    "        if row.Monat['min'] != row.Monat['max']:\n",
    "            val = 1\n",
    "        elif  row.Tag['min'] != row.Tag['max']:\n",
    "            val = 1\n",
    "        elif  row.Time['min'] != row.Time['max']:\n",
    "            if ((pd.to_datetime(row.Time['min']) + pd.to_timedelta(45, unit='m')) < pd.to_datetime(row.Time['max'])):\n",
    "                val = 1\n",
    "            else:\n",
    "                val = 0\n",
    "        else:\n",
    "            val = 0\n",
    "        return val\n",
    "\n",
    "    df_gr['luecke'] = df_gr.apply(f, axis=1)\n",
    "    df_gr.to_pickle('xmlsentences'+num+'_luecke.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "From Break Variable and Ordernumber information, the session nr is determined\n",
    "session number = number of the session, when the user drops out and continues later\n",
    "run code for all datasets (1-10)\n",
    "\"\"\"\n",
    "\n",
    "## load and prepare break information (SessionID and Break)\n",
    "infile = open('files/xmlsentences1_luecke.pkl','rb')\n",
    "xmlsentences1_luecke = pickle.load(infile)\n",
    "infile.close()\n",
    "xmlsentences1_luecke.columns = xmlsentences1_luecke.columns.droplevel(1)\n",
    "xmlsentences1_luecke = xmlsentences1_luecke[['UebungsID','luecke']]\n",
    "\n",
    "## load and prepare ordernumber of the sentence\n",
    "infile = open('files/xmlsentences1_ordernumber.pkl','rb')\n",
    "xmlsentences1_ordernumber = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "## merge dataframe\n",
    "xmlsentences1_merged = pd.merge(xmlsentences1_ordernumber, xmlsentences1_luecke, on='UebungsID')\n",
    "\n",
    "## split by break\n",
    "xmlsentences1_luecke0 = xmlsentences1_merged[xmlsentences1_merged.luecke==0]\n",
    "xmlsentences1_luecke1 = xmlsentences1_merged[xmlsentences1_merged.luecke==1]\n",
    "\n",
    "## add variable session number = 1 when there is no break \n",
    "xmlsentences1_luecke0['sessionNr'] = 1\n",
    "\n",
    "## calculate if a break is between two sentences from a session\n",
    "## return 1 if there was a break, 0 if there was no break \n",
    "def check_if_break(aktuelltag, aktuellmonat, aktuelluhrzeit, vergleichtag, vergleichmonat, vergleichuhrzeit):\n",
    "    if aktuellmonat.values[0] != vergleichmonat.values[0]:\n",
    "        val = 1\n",
    "    elif  aktuelltag.values[0] != vergleichtag.values[0]:\n",
    "        val = 1\n",
    "    elif  aktuelluhrzeit.values[0] != vergleichuhrzeit.values[0]:\n",
    "        if (vergleichuhrzeit.values[0]+3) < aktuelluhrzeit.values[0]:\n",
    "            val = 1\n",
    "        else:\n",
    "            val= 0\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "## prepare sessions where there is a dropout\n",
    "errorlist = []\n",
    "xml_with_breaks = xmlsentences1_luecke1\n",
    "xml_with_breaks = xml_with_breaks.astype({'UebungsID': str})\n",
    "xml_with_breaks['sessionNr'] = 0\n",
    "session = xml_with_breaks.UebungsID.unique()\n",
    "\n",
    "for x in session:\n",
    "    try:\n",
    "        ## get count of sentences per session\n",
    "        anzahl = len(xml_with_breaks.loc[xml_with_breaks['UebungsID'] == x])\n",
    "\n",
    "        ## get information from first sentence -> is definetly in session nr 1\n",
    "        nr1 = xml_with_breaks.loc[(xml_with_breaks['UebungsID'] == x) & (xml_with_breaks.OrderNumber == 1)] \n",
    "        id1 = nr1.ID\n",
    "        xml_with_breaks.loc[(xml_with_breaks.ID.values == id1.values), 'sessionNr'] = 1\n",
    "        vergleichmonat = xml_with_breaks['Monat'].loc[(xml_with_breaks['UebungsID'] == x) & (xml_with_breaks.OrderNumber == 1)] \n",
    "        vergleichtag = xml_with_breaks['Tag'].loc[(xml_with_breaks['UebungsID'] == x) & (xml_with_breaks.OrderNumber == 1)]    \n",
    "        vergleichuhrzeit = xml_with_breaks['Uhrzeit'].loc[(xml_with_breaks['UebungsID'] == x) & (xml_with_breaks.OrderNumber == 1)] \n",
    "\n",
    "        session = 1\n",
    "\n",
    "        ## for each sentence in session\n",
    "        for y in range(anzahl-1):\n",
    "            ## get current sentence\n",
    "            a = y+2\n",
    "            nr = xml_with_breaks.loc[(xml_with_breaks['UebungsID'] == x) & (xml_with_breaks.OrderNumber == a)]\n",
    "            this_id = nr.ID\n",
    "            ## get date from current sentence\n",
    "            aktuelltag = nr['Tag']\n",
    "            aktuellmonat = nr['Monat']\n",
    "            aktuelluhrzeit = nr['Uhrzeit']\n",
    "\n",
    "            ## check if there is a break\n",
    "            is_break = check_if_break(aktuelltag, aktuellmonat, aktuelluhrzeit, vergleichtag, vergleichmonat, vergleichuhrzeit)\n",
    "\n",
    "            ## save session nr \n",
    "            if is_break == 1:\n",
    "                xml_with_breaks.loc[(xml_with_breaks.ID.values == this_id.values), 'sessionNr'] = session+1\n",
    "                session = session+1\n",
    "            else:\n",
    "                xml_with_breaks.loc[(xml_with_breaks.ID.values == this_id.values), 'sessionNr'] = session\n",
    "\n",
    "            ## update date information to compare to the next sentence\n",
    "            vergleichmonat = aktuellmonat\n",
    "            vergleichtag = aktuelltag\n",
    "            vergleichuhrzeit = aktuelluhrzeit\n",
    "\n",
    "    except:\n",
    "        print(x)\n",
    "\n",
    "# save dataframe with new variable\n",
    "xml_with_breaks.to_pickle('xmlsentences1_sessionnr1.pkl')\n",
    "xmlsentences1_luecke0.to_pickle('xmlsatze1_sessionnr0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Finish dataset: new UebungsID, recalculate Ordernumber\n",
    "run code for all datasets\n",
    "\"\"\"\n",
    "\n",
    "## load and append datasets\n",
    "infile = open('xmlsentences1_sessionnr1.pkl','rb')\n",
    "xmlsentences1_sessionnr1 = pickle.load(infile)\n",
    "infile.close()\n",
    "infile = open('xmlsentences1_sessionnr0.pkl','rb')\n",
    "xmlsentences1_sessionnr0 = pickle.load(infile)\n",
    "infile.close()\n",
    "new_session_nr = xmlsentences1_sessionnr1.append(xmlsentences1_sessionnr0)\n",
    "\n",
    "## Concatenate SessionNr to UebungsID \n",
    "new_session_nr['sessionNr'] = new_session_nr['sessionNr'].astype(str)\n",
    "new_session_nr[\"UebungsID\"] = new_session_nr[\"UebungsID\"].map(str) + \"_\" + new_session_nr[\"sessionNr\"]\n",
    "\n",
    "## Recalculate ordernumber -> if there was a dropout, the second session begins with ordernumber 1\n",
    "min_ordernr = new_session_nr.groupby('UebungsID')['OrderNumber'].min()\n",
    "new_order = pd.merge(new_session_nr, min_ordernr, on='UebungsID')\n",
    "new_order['OrderNumber_y'] = new_order['OrderNumber_y'] - 1\n",
    "new_order['OrderNumber'] = new_order['OrderNumber_x'] - new_order['OrderNumber_y']\n",
    "new_order = new_order.drop(columns=['OrderNumber_x', 'OrderNumber_y'])\n",
    "\n",
    "## Create new column: dropped out before \n",
    "## if it is a second, third, fourth... session, this column indicates if the exercise was processed in more than one session\n",
    "def f(row):\n",
    "    if row['sessionNr'] != '1':\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "new_order['vorher_abgebrochen'] = new_order.apply(f, axis=1)\n",
    "new_order.to_pickle('vacay_preprocessed1.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
